{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Для решения задачи рекомендации на основе MovieLens я выбрал библиотеку Pytorch и подход NCF. Мы будем тестироваться на рекомендации(подборке) 10 фильмов для каждого пользователя.Данные для обучения я предварительно загрузил на гугл диск для удобного доступа из colab. Далее, в классе UserItemRatingDataset я сделал представление наших данных в виде torch.tensor.\n",
        "\n",
        "Я решил перевести Excplicit feedback в Implicit(т.е. оценки пользователями фильмов в бинарную метрику поставил оценку/не поставил), обычно Implicit feedbackа гораздо больше, поэтому было бы разумно сразу обучать модель так. \n",
        "В классе NCFData я создаю данные для обучения/тестирования. Важно отметить, что нам нужно вручную создать для пользователей отрицательные примеры(сейчас мы знаем только про положительные, т.е. оценки от пользователей). Для этого случайно будет добавлять к пользователем фильмы, которые он не оценил.\n",
        "Для тестирования будем использовать подход Leave One Out, то есть тестировать на основе последней оценки фильма от пользователя.\n",
        "\n",
        "К сожалению, при полной загрузке датасета MovieLens 25m вылетает оперативная память, так что я ограничусь примерно 500к оценок(если необходимо, при больших вычислительных мощностях можно засунуть и полный датасет).\n",
        "\n",
        "Для оценки качества модели я выбрал метрики Hit(попадание релевантного элемента в рекомендуемые, без учета их ранжирования) и nDCG(normalized Discounted Cumulative Gain), где уже учитывается ранжирование(т.е. более релевантные элементы должны быть выше в списке рекомендаций). \n",
        "\n",
        "Далее я реализовал модель GMF(матричное разложение матрицы пользователей и фильмов). С помощью nn.Embeddings мы создаем два эмбеддинга пользователей и фильмов, перемножаем их поэлементно и пропускаем через полносвязный слой с активацией сигмоида.\n",
        "\n",
        "В конце, обучаем нашу нейронную сеть с помощью train_pipeline и смотрим на средние значения метрик Hit и nDCG на каждой эпохе.\n",
        "Уже после нескольких эпох мы достигаем неплохо качества Hit и nDCG(порядка 0.8 и 0.5 уже на 2 эпохе). Это достаточно хорошо, так как получается для 80% пользователей мы смогли порекомендовать такие фильмы, что они посмотрели и оценили хотя-бы один из них."
      ],
      "metadata": {
        "id": "Ynj4zpxrHZya"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "5Hq0fDqXN8Lp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gL9jn8aRwpif",
        "outputId": "ba0b6b4e-1ede-48c4-daa2-8c4f2a6165c3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "TOP_K = 10"
      ],
      "metadata": {
        "id": "uEGUFBbtN8Lu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "source": [
        "class UserItemRatingDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Делаем тензоры из наших данных\n",
        "    \"\"\"\n",
        "    def __init__(self, user_list, item_list, rating_list):\n",
        "        super(UserItemRatingDataset, self).__init__()\n",
        "        self.user_tensor = torch.tensor(user_list, dtype=torch.long)\n",
        "        self.item_tensor = torch.tensor(item_list, dtype=torch.long)\n",
        "        self.target_tensor = torch.tensor(rating_list, dtype=torch.float)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.target_tensor)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.user_tensor[idx], self.item_tensor[idx], self.target_tensor[idx]"
      ],
      "metadata": {
        "id": "lDyh9HZqN8Lu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "source": [
        "class NCFData(object):\n",
        "    \"\"\"\n",
        "    Собираем данные для обучения модели\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ratings, num_negatives, num_negatives_test, batch_size):\n",
        "        self.ratings = ratings\n",
        "        self.num_negatives = num_negatives\n",
        "        self.num_negatives_test = num_negatives_test\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.preprocess_ratings = self._reindex(self.ratings)\n",
        "        self.user_pool = set(self.ratings['user_id'].unique())\n",
        "        self.item_pool = set(self.ratings['item_id'].unique())\n",
        "\n",
        "        self.train_ratings, self.test_ratings = self._leave_one_out(self.preprocess_ratings)\n",
        "        self.negatives = self._negative_sampling(self.preprocess_ratings)\n",
        "\n",
        "    def _reindex(self, ratings):\n",
        "        \"\"\"\n",
        "        Перенумеровываем данные, так как изначально у нас идут произвольные индексы\n",
        "        \"\"\"\n",
        "        user_list = list(ratings['user_id'].drop_duplicates())\n",
        "        self.user2id = {w: i for i, w in enumerate(user_list)}\n",
        "\n",
        "        item_list = list(ratings['item_id'].drop_duplicates())\n",
        "        self.item2id = {w: i for i, w in enumerate(item_list)}\n",
        "\n",
        "        ratings['user_id'] = ratings['user_id'].apply(lambda x: self.user2id[x])\n",
        "        ratings['item_id'] = ratings['item_id'].apply(lambda x: self.item2id[x])\n",
        "        ratings['rating'] = ratings['rating'].apply(lambda x: float(x > 0))\n",
        "        return ratings\n",
        "\n",
        "    def _leave_one_out(self, ratings):\n",
        "        \"\"\"\n",
        "        Хотим тестировать на последнем фильме, который пользователь оценил\n",
        "        \"\"\"\n",
        "        ratings['rank_latest'] = ratings.groupby(['user_id'])['timestamp'].rank(method='first', ascending=False)\n",
        "        test = ratings.loc[ratings['rank_latest'] == 1]\n",
        "        train = ratings.loc[ratings['rank_latest'] > 1]\n",
        "        test = test[test['user_id'].isin(train['user_id'].unique())]\n",
        "        print(train['user_id'].nunique(), test['user_id'].nunique())\n",
        "        assert train['user_id'].nunique() == test['user_id'].nunique(), 'Not Match Train User with Test User'\n",
        "        return train[['user_id', 'item_id', 'rating']], test[['user_id', 'item_id', 'rating']]\n",
        "\n",
        "    def _negative_sampling(self, ratings):\n",
        "        \"\"\"\n",
        "        Для всех пользователей создаем какие-то негативные примеры(т.е. фильмы, которые он ещё не оценивал)\n",
        "        \"\"\"\n",
        "        interact_status = (ratings.groupby('user_id')['item_id'].apply(set).reset_index().rename(\n",
        "            columns={'item_id': 'interacted_items'}))\n",
        "        interact_status['negative_items'] = (interact_status['interacted_items'].apply(lambda x: self.item_pool - x))\n",
        "        interact_status['negative_samples'] = (\n",
        "            interact_status['negative_items'].apply(lambda x: random.choices(tuple(x), k=self.num_negatives_test)))\n",
        "        return interact_status[['user_id', 'negative_items', 'negative_samples']]\n",
        "\n",
        "    def get_train_instance(self):\n",
        "        \"\"\"\n",
        "        Собираем это все вместе и конструируем данные для обучения\n",
        "        \"\"\"\n",
        "        users, items, ratings = [], [], []\n",
        "        train_ratings = pd.merge(self.train_ratings, self.negatives[['user_id', 'negative_items']], on='user_id')\n",
        "        train_ratings['negatives'] = train_ratings['negative_items'].apply(\n",
        "            lambda x: random.choices(tuple(x), k=self.num_negatives))\n",
        "        for row in train_ratings.itertuples():\n",
        "            users.append(int(row.user_id))\n",
        "            items.append(int(row.item_id))\n",
        "            ratings.append(float(row.rating))\n",
        "            for i in range(self.num_negatives):\n",
        "                users.append(int(row.user_id))\n",
        "                items.append(int(row.negatives[i]))\n",
        "                ratings.append(float(0))  # negative samples get 0 rating\n",
        "\n",
        "        dataset = UserItemRatingDataset(user_list=users, item_list=items, rating_list=ratings)\n",
        "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "    def get_test_instance(self):\n",
        "        \"\"\"\n",
        "        Собираем данные примерно так же для тестирования\n",
        "        \"\"\"\n",
        "        users, items, ratings = [], [], []\n",
        "        test_ratings = pd.merge(self.test_ratings, self.negatives[['user_id', 'negative_samples']], on='user_id')\n",
        "        for row in test_ratings.itertuples():\n",
        "            users.append(int(row.user_id))\n",
        "            items.append(int(row.item_id))\n",
        "            ratings.append(float(row.rating))\n",
        "            for i in getattr(row, 'negative_samples'):\n",
        "                users.append(int(row.user_id))\n",
        "                items.append(int(i))\n",
        "                ratings.append(float(0))\n",
        "\n",
        "        dataset = UserItemRatingDataset(user_list=users, item_list=items, rating_list=ratings)\n",
        "        return DataLoader(dataset, batch_size=self.num_negatives_test + 1, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "AMheJW5TN8Lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml = pd.read_csv('drive/MyDrive/Colab Notebooks/ml-latest/ratings.csv').rename(columns={'userId': 'user_id', 'movieId': 'item_id'})"
      ],
      "metadata": {
        "id": "JLhpej601Byx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Я изменил тип данных в каждой из колонок чтобы сэкономить оперативную память(но это не помогло)\n",
        "#После этого просто обрезал датасет\n",
        "ml['rating'] = (ml['rating'] * 2).astype('int8')\n",
        "ml['user_id'] = ml['user_id'].astype('int32')\n",
        "ml['item_id'] = ml['item_id'].astype('int32')\n",
        "ml = ml.iloc[:27753444//50]"
      ],
      "metadata": {
        "id": "ITUZCGFpybyV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "source": [
        "#получим количество фильмов и пользователей\n",
        "num_users = ml['user_id'].nunique() + 1\n",
        "num_items = ml['item_id'].nunique() + 1"
      ],
      "metadata": {
        "id": "47WpUazZN8Lx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5498 5498\n"
          ]
        }
      ],
      "source": [
        "data = NCFData(ml, num_negatives=4, num_negatives_test=100, batch_size=1024)"
      ],
      "metadata": {
        "id": "zT7VQIO2N8L0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d2d4b26-8814-491b-9959-65ede7085460"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "source": [
        "def hit(ng_item, pred_items):\n",
        "    \"\"\"\n",
        "    Метрика попадание(без учета ранжирования)\n",
        "    \"\"\"\n",
        "    if ng_item in pred_items:\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "\n",
        "def ndcg(ng_item, pred_items):\n",
        "    \"\"\"\n",
        "    Метрика попадния с учетом ранжирования\n",
        "    \"\"\"\n",
        "    if ng_item in pred_items:\n",
        "        index = pred_items.index(ng_item)\n",
        "        return np.reciprocal(np.log2(index + 2))\n",
        "    return 0\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def metrics(model, test_loader, top_k, device):\n",
        "    \"\"\"\n",
        "    Соберем все метрики для каждого пользователя и усредним\n",
        "    \"\"\"\n",
        "    _hr, _ndcg = [], []\n",
        "\n",
        "    for user, item, label in test_loader:\n",
        "        user = user.to(device)\n",
        "        item = item.to(device)\n",
        "\n",
        "        predictions = model(user, item)\n",
        "        predictions = predictions.view(-1)\n",
        "        _, indices = torch.topk(predictions, top_k)\n",
        "        recommends = torch.take(item, indices).cpu().numpy().tolist()\n",
        "\n",
        "        ng_item = item[0].item()  # leave one-out evaluation has only one item per user\n",
        "        _hr.append(hit(ng_item, recommends))\n",
        "        _ndcg.append(ndcg(ng_item, recommends))\n",
        "\n",
        "    return np.mean(_hr), np.mean(_ndcg)"
      ],
      "metadata": {
        "id": "kiEReIMKN8L1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "source": [
        "class GMF(nn.Module):\n",
        "    \"\"\"\n",
        "    Строим архитектуру GMF как описывали в начале\n",
        "    \"\"\"\n",
        "    def __init__(self, num_users, num_items, embedding_dim):\n",
        "        super(GMF, self).__init__()\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.embedding_user = nn.Embedding(num_embeddings=num_users, embedding_dim=embedding_dim)\n",
        "        self.embedding_item = nn.Embedding(num_embeddings=num_items, embedding_dim=embedding_dim)\n",
        "        self.affine_output = nn.Linear(in_features=embedding_dim, out_features=1)\n",
        "        self.logistic = nn.Sigmoid()\n",
        "\n",
        "        self.init_weight()\n",
        "\n",
        "    def forward(self, user_indices, item_indices):\n",
        "        user_embedding = self.embedding_user(user_indices)\n",
        "        item_embedding = self.embedding_item(item_indices)\n",
        "        element_product = torch.mul(user_embedding, item_embedding)\n",
        "        logits = self.affine_output(element_product)\n",
        "        rating = self.logistic(logits)\n",
        "        return rating\n",
        "\n",
        "    def init_weight(self):\n",
        "        \"\"\"\n",
        "        Для улучшения обучения и получения быстрее хороших значений метрик инициализируем веса с помощью Xavier Uniform\n",
        "        \"\"\"\n",
        "        nn.init.xavier_uniform_(self.embedding_user.weight)\n",
        "        nn.init.xavier_uniform_(self.embedding_item.weight)"
      ],
      "metadata": {
        "id": "77xClpNCN8L1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "source": [
        "def train_pipeline(model, optimizer, criterion, data, num_epochs):\n",
        "    \"\"\"\n",
        "    Обучаем модель, с накоплением истории изменения метрик и удобным выводом с помощью tqdm\n",
        "    \"\"\"\n",
        "    loss_history = []\n",
        "    metrics_history = {'HR@10': [], 'NDCG@10': []}\n",
        "    test_loader = data.get_test_instance()\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        model.train() \n",
        "        train_loader = data.get_train_instance()\n",
        "\n",
        "        for user, item, label in tqdm.tqdm(train_loader, desc=f'[Epoch #{epoch}]',total=len(train_loader)):\n",
        "            user = user.to(DEVICE)\n",
        "            item = item.to(DEVICE)\n",
        "            label = label.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            prediction = model(user, item)\n",
        "\n",
        "            loss = criterion(prediction.view(-1), label.view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_history.append(loss.item())\n",
        "\n",
        "        # Накапливаем метрики\n",
        "        model.eval()\n",
        "        hr_i, ndcg_i = metrics(model, test_loader, TOP_K, DEVICE)\n",
        "        metrics_history['HR@10'].append(hr_i)\n",
        "        metrics_history['NDCG@10'].append(ndcg_i)\n",
        "\n",
        "        print(f\"[Epoch #{epoch}] HR: {hr_i:.3f}\\ndcg: {ndcg_i:.3f}\")\n",
        "\n",
        "    return loss_history, metrics_history"
      ],
      "metadata": {
        "id": "-KMqCHSjN8L2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "source": [
        "#Выбираем как критерий бинарную кросс энтропию что типично для задач бинарной классификации\n",
        "# И стандартный оптимизатор Adam\n",
        "model = GMF(num_users=num_users, num_items=num_items, embedding_dim=32)\n",
        "model = model.to(DEVICE)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "1m3AN-KSN8L2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch #1]: 100%|██████████| 2683/2683 [03:17<00:00, 13.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch #1] HR: 0.784\n",
            "dcg: 0.505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch #2]: 100%|██████████| 2683/2683 [03:19<00:00, 13.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch #2] HR: 0.818\n",
            "dcg: 0.539\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-7e8d4d807fbf>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-3a20e08c0f5b>\u001b[0m in \u001b[0;36mtrain_pipeline\u001b[0;34m(model, optimizer, criterion, data, num_epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_train_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'[Epoch #{epoch}]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-cfd10e00743a>\u001b[0m in \u001b[0;36mget_train_instance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mtrain_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegatives\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'negative_items'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         train_ratings['negatives'] = train_ratings['negative_items'].apply(\n\u001b[0m\u001b[1;32m     64\u001b[0m             lambda x: random.choices(tuple(x), k=self.num_negatives))\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitertuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[0;32m-> 4771\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4773\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-cfd10e00743a>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mtrain_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegatives\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'negative_items'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         train_ratings['negatives'] = train_ratings['negative_items'].apply(\n\u001b[0;32m---> 64\u001b[0;31m             lambda x: random.choices(tuple(x), k=self.num_negatives))\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitertuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0musers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "loss_history, metrics_history = train_pipeline(model, optimizer, criterion, data, num_epochs=10)"
      ],
      "metadata": {
        "id": "ZJumEWlMN8L3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "c314c1ac-85a6-4512-e5d7-c87a7d898d51"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}